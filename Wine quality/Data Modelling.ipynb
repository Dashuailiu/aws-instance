{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "# If you're using VirtualBox, change the below to '/home/user/spark-2.1.1-bin-hadoop2.7'\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "\n",
    "# If you're getting an error with numpy, please type 'sudo pip3 install numpy --user' into the console.\n",
    "# If you're getting an error with another package, type 'sudo pip3 install PACKAGENAME --user'. \n",
    "# Replace PACKAGENAME with the relevant package (such as pandas, etc).\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('data_modelling_wq').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fixed acidity: double (nullable = true)\n",
      " |-- volatile acidity: double (nullable = true)\n",
      " |-- citric acid: double (nullable = true)\n",
      " |-- residual sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free sulfur dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- Wine color: string (nullable = true)\n",
      " |-- quality: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.200831</td>\n",
       "      <td>0.336697</td>\n",
       "      <td>0.312763</td>\n",
       "      <td>5.163375</td>\n",
       "      <td>0.053538</td>\n",
       "      <td>30.165777</td>\n",
       "      <td>0.994534</td>\n",
       "      <td>3.225481</td>\n",
       "      <td>0.526145</td>\n",
       "      <td>10.551699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.257394</td>\n",
       "      <td>0.162306</td>\n",
       "      <td>0.135072</td>\n",
       "      <td>4.535988</td>\n",
       "      <td>0.026393</td>\n",
       "      <td>17.643337</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.132850</td>\n",
       "      <td>1.165721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.992230</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.994610</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>14.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4871.000000       4871.000000  4871.000000     4871.000000   \n",
       "mean        7.200831          0.336697     0.312763        5.163375   \n",
       "std         1.257394          0.162306     0.135072        4.535988   \n",
       "min         4.400000          0.080000     0.000000        0.600000   \n",
       "25%         6.400000          0.230000     0.250000        1.800000   \n",
       "50%         7.000000          0.290000     0.310000        2.800000   \n",
       "75%         7.700000          0.390000     0.390000        7.700000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide      density           pH  \\\n",
       "count  4871.000000          4871.000000  4871.000000  4871.000000   \n",
       "mean      0.053538            30.165777     0.994534     3.225481   \n",
       "std       0.026393            17.643337     0.002923     0.151659   \n",
       "min       0.012000             1.000000     0.987110     2.790000   \n",
       "25%       0.038000            17.000000     0.992230     3.120000   \n",
       "50%       0.047000            28.000000     0.994610     3.220000   \n",
       "75%       0.063000            41.000000     0.996750     3.330000   \n",
       "max       0.415000           289.000000     1.038980     3.750000   \n",
       "\n",
       "         sulphates      alcohol  \n",
       "count  4871.000000  4871.000000  \n",
       "mean      0.526145    10.551699  \n",
       "std       0.132850     1.165721  \n",
       "min       0.220000     8.400000  \n",
       "25%       0.430000     9.500000  \n",
       "50%       0.510000    10.400000  \n",
       "75%       0.600000    11.300000  \n",
       "max       1.980000    14.200000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data and print schema - columns is another way to view the data's features.\n",
    "df = spark.read.csv('clean_data.csv', header=True, inferSchema=True)\n",
    "# df = spark.read.csv('clean_data2.csv', header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "df.toPandas().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a string indexer which converts every string into a number, such as male = 0 and female = 1.\n",
    "# A number will be assigned to every category in the column.\n",
    "wine_color_indexer = StringIndexer(inputCol='Wine color',outputCol='wine_colorIndex')\n",
    "quality_indexer = StringIndexer(inputCol='quality',outputCol='label')\n",
    "\n",
    "# Now we can one hot encode these numbers. This converts the various outputs into a single vector.\n",
    "# Multiple columns are collapsed into one. \n",
    "# This makes it easier to process when you have multiple classes.\n",
    "wine_color_encoder = OneHotEncoder(inputCol='wine_colorIndex',outputCol='wine_colorVec')\n",
    "# quality_encoder = OneHotEncoder(inputCol='qualityIndex',outputCol='qualityVec')\n",
    "\n",
    "# And finally, using vector assembler to turn all of these columns into one column (named features).\n",
    "assembler = VectorAssembler(inputCols=['fixed acidity','volatile acidity','citric acid','residual sugar',\n",
    "                                       'chlorides','free sulfur dioxide','density','pH',\n",
    "                                       'sulphates', 'alcohol', 'wine_colorVec'], outputCol=\"features\")\n",
    "# assembler = VectorAssembler(inputCols=['fixed acidity','volatile acidity','citric acid','residual sugar',\n",
    "#                                        'chlorides','free sulfur dioxide','total sulfur dioxide','density','pH',\n",
    "#                                        'sulphates', 'alcohol', 'wine_colorVec'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-------+-----+\n",
      "|Wine color|wine_colorIndex|quality|label|\n",
      "+----------+---------------+-------+-----+\n",
      "|     White|            0.0|    bad|  1.0|\n",
      "|       Red|            1.0|    bad|  1.0|\n",
      "|       Red|            1.0|   good|  0.0|\n",
      "|     White|            0.0|   good|  0.0|\n",
      "|     White|            0.0|   good|  0.0|\n",
      "|     White|            0.0|   good|  0.0|\n",
      "|     White|            0.0|    bad|  1.0|\n",
      "|     White|            0.0|    bad|  1.0|\n",
      "|       Red|            1.0|   good|  0.0|\n",
      "|       Red|            1.0|    bad|  1.0|\n",
      "|     White|            0.0|   good|  0.0|\n",
      "|     White|            0.0|    bad|  1.0|\n",
      "|       Red|            1.0|   good|  0.0|\n",
      "|     White|            0.0|   good|  0.0|\n",
      "|     White|            0.0|   good|  0.0|\n",
      "|       Red|            1.0|   good|  0.0|\n",
      "|       Red|            1.0|   good|  0.0|\n",
      "|     White|            0.0|    bad|  1.0|\n",
      "|     White|            0.0|   good|  0.0|\n",
      "|       Red|            1.0|   good|  0.0|\n",
      "+----------+---------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(label=1.0, features=DenseVector([6.0, 0.28, 0.29, 19.3, 0.051, 36.0, 0.9991, 3.14, 0.5, 9.0, 1.0]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then go through our steps. It's essentially sequential to the above.\n",
    "pipeline = Pipeline(stages=[wine_color_indexer, quality_indexer, wine_color_encoder, assembler])\n",
    "# Now that we've got a number of steps, let's apply it to the DataFrame.\n",
    "pipeline_model = pipeline.fit(df)\n",
    "\n",
    "# Incorporate results into a new DataFrame.\n",
    "pipe_df = pipeline_model.transform(df)\n",
    "\n",
    "# Remove all variables other than features and label. \n",
    "pipe_df.select('Wine color', 'wine_colorIndex', 'quality', 'label').show()\n",
    "pipe_df = pipe_df.select('label', 'features')\n",
    "pipe_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_indicators(predictions, col_name):\n",
    "    tp = predictions.filter(\"label = prediction and label=0.0\").count()\n",
    "    tn = predictions.filter(\"label = prediction and label=1.0\").count()\n",
    "    fp = predictions.filter(\"label <> prediction and label=0.0\").count()\n",
    "    fn = predictions.filter(\"label <> prediction and label=1.0\").count()\n",
    "    num = predictions.count()\n",
    "    acc = (tp+tn)/num\n",
    "    pre = tp/(tp+fp)\n",
    "    rec = tp/(tp+fn)\n",
    "    eval_dict = {\n",
    "        'Accuracy': acc,\n",
    "        'Precision': pre,\n",
    "        'Recall': rec,\n",
    "        'F1-score': 2*pre*rec/(pre+rec)\n",
    "    }\n",
    "    eval_pd = pd.DataFrame.from_dict(eval_dict, orient='index')\n",
    "    eval_pd.columns = [col_name]\n",
    "    return eval_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(featuresCol='features', \\\n",
    "                                  labelCol='label',\n",
    "                                  maxDepth=5) \n",
    "\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=dt_model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel_dt = cv.fit(pipe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = cvModel_dt.bestModel\n",
    "\n",
    "dt_mol = dt_model.transform(pipe_df)\n",
    "eva_dt = evaluate_indicators(dt_mol, \"DecisionTreeClassifier(Cross validation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_i_dt = dt_model.featureImportances\n",
    "pd.DataFrame(feature_i_dt.toArray(), index=['fixed acidity','volatile acidity','citric acid','residual sugar',\n",
    "                      'chlorides','free sulfur dioxide','density','pH',\n",
    "                      'sulphates', 'alcohol', 'wine_colorVec'], columns=[\"importance\"]).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(\"Area Under ROC: \" + str(evaluator.evaluate(dt_mol, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "sns.countplot(x='label', data=dt_mol.filter('label <> prediction').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(featuresCol='features', \\\n",
    "                              labelCol='label', \\\n",
    "                              regParam=0.0, \\\n",
    "                              elasticNetParam=0.0, \\\n",
    "                              maxIter=100) \n",
    "\n",
    "paramGrid=ParamGridBuilder().build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=lr_model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel_lr = cv.fit(pipe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_res = cvModel_lr.bestModel.summary.predictions\n",
    "eva_lr = evaluate_indicators(lr_res, \"LogisticRegression(Cross validation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel_summary = cvModel_lr.bestModel.summary\n",
    "\n",
    "# training_summary.accuracy.show()\n",
    "# Convert the DataFrame to a Pandas DataFrame.\n",
    "ROC = bestModel_summary.roc.toPandas()\n",
    "# Plot the true positive and false positive rates.\n",
    "sns.lineplot(x='FPR', y='TPR', data=ROC)\n",
    "\n",
    "# Define the labels.\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Print the AUC statistic. \n",
    "print('Area Under the Curve: ' + str(bestModel_summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More iteration\n",
    "lr_model = LogisticRegression(featuresCol='features',labelCol='label') \n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(lr_model.regParam, [0.0, 0.3]).\\\n",
    "addGrid(lr_model.elasticNetParam, [0.0, 0.8]).\\\n",
    "addGrid(lr_model.maxIter, [100, 10]).build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=lr_model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(pipe_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_res = cvModel.bestModel.summary.predictions\n",
    "evaluate_indicators(lr_res, \"LogisticRegression(Cross validation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "# Instantiate the model.\n",
    "rf_model = RandomForestClassifier(featuresCol='features',\\\n",
    "                                  labelCol='label', \\\n",
    "                                  maxDepth=5, \n",
    "                                  numTrees=20)\n",
    "\n",
    "paramGrid=ParamGridBuilder().build()\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=rf_model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel_rf = cv.fit(pipe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = cvModel_rf.bestModel\n",
    "\n",
    "rf_mol = rf_model.transform(pipe_df)\n",
    "eva_rf = evaluate_indicators(rf_mol, \"RandomForestClassifier(Cross validation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_i_rf = rf_model.featureImportances\n",
    "pd.DataFrame(feature_i_rf.toArray(), index=['fixed acidity','volatile acidity','citric acid','residual sugar',\n",
    "                      'chlorides','free sulfur dioxide','density','pH',\n",
    "                      'sulphates', 'alcohol', 'wine_colorVec'], columns=[\"importance\"]).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(\"Area Under ROC: \" + str(evaluator.evaluate(rf_mol, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "sns.countplot(x='label', data=rf_mol.filter('label <> prediction').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "# Instantiate the model.\n",
    "rf_model = RandomForestClassifier(featuresCol='features',\\\n",
    "                                  labelCol='label')\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(rf_model.numTrees, [i for i in range(15, 25)]).build()\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=rf_model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(pipe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier(Cross validation)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.853181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.827401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.776021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.803133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RandomForestClassifier(Cross validation)\n",
       "Precision                                  0.853181\n",
       "F1-score                                   0.827401\n",
       "Accuracy                                   0.776021\n",
       "Recall                                     0.803133"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfs_model = cvModel.bestModel\n",
    "\n",
    "rfs_mol = rfs_model.transform(pipe_df)\n",
    "evaluate_indicators(rfs_mol, \"RandomForestClassifier(Cross validation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting tree \n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt_model = GBTClassifier(labelCol=\"label\", \\\n",
    "                          featuresCol=\"features\", \\\n",
    "                          maxIter=10)\n",
    "paramGrid=ParamGridBuilder().build()\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=gbt_model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel_gbt = cv.fit(pipe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model = cvModel_gbt.bestModel\n",
    "\n",
    "gbt_mol = gbt_model.transform(pipe_df)\n",
    "eva_gbt = evaluate_indicators(gbt_mol, \"GBTClassifier(Cross validation)\")\n",
    "feature_i = gbt_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(feature_i.toArray(), index=['fixed acidity','volatile acidity','citric acid','residual sugar',\n",
    "                      'chlorides','free sulfur dioxide','density','pH',\n",
    "                      'sulphates', 'alcohol', 'wine_colorVec'], columns=[\"importance\"]).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", \\\n",
    "                                          rawPredictionCol=\"prediction\")\n",
    "print(type(gbt_model))\n",
    "gbt_mol.printSchema()\n",
    "print(\"Area Under ROC: \" + str(evaluator.evaluate(gbt_mol, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='label', data=gbt_mol.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "gbt_mol.show()\n",
    "sns.countplot(x='label', data=gbt_mol.filter('label <> prediction').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "gbt_model = GBTClassifier(labelCol=\"label\", \\\n",
    "                          featuresCol=\"features\")\n",
    "paramGrid=ParamGridBuilder().addGrid(gbt_model.maxIter, [i for i in range(10, 18)]).build()\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=gbt_model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel_gbts = cv.fit(pipe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbts_model = cvModel_gbts.bestModel\n",
    "\n",
    "gbts_mol = gbts_model.transform(pipe_df)\n",
    "evaluate_indicators(gbts_mol, \"GBTClassifier(Cross validation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([eva_dt,eva_lr,eva_rf,eva_gbt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([eva_gbt,eva_rf,eva_dt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb_model = NaiveBayes(labelCol=\"label\", \\\n",
    "                          featuresCol=\"features\", smoothing=1.0)\n",
    "paramGrid=ParamGridBuilder().build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=nb_model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel_nb = cv.fit(pipe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           NaiveBayes(Cross validation)\n",
      "Precision                      0.853181\n",
      "F1-score                       0.738909\n",
      "Accuracy                       0.620612\n",
      "Recall                         0.651632\n"
     ]
    }
   ],
   "source": [
    "nb_model = cvModel_nb.bestModel\n",
    "\n",
    "nb_mol = nb_model.transform(pipe_df)\n",
    "eva_gbt = evaluate_indicators(nb_mol, \"NaiveBayes(Cross validation)\")\n",
    "print(eva_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
